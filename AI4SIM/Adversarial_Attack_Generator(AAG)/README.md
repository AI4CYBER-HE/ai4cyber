# AAG - Adversarial Attack Generator

## Introduction
The **Adversarial Attack Generator (AAG)** is a modular tool designed to test the robustness of AI models used in encrypted traffic analysis and intrusion detection.  
It allows users to inject adversarial perturbations into clean input samples and evaluate how models perform under inference-time attacks.  
AAG includes:
- A **Strategy Library** of attack methods
- An **Adversarial Attack Engine** for generating perturbed inputs
- An **Evaluation Module** that measures resilience using metrics such as Accuracy, F1-score, TPR, FPR, and Impact Score  

The tool also provides a **user-friendly dashboard** for configuring attack parameters, launching simulations, and visualizing results, making it accessible to both researchers and practitioners.

## Repository
ðŸ”— [Access the AAG Tool here](https://gitlab.ithaca.ece.uowm.gr/ai4cyber/adversarial-attack-generator/-/tree/master?ref_type=headsG)  
